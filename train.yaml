output:
  # The finetuned model name will be the base model name plus a suffix
  suffix: '-TESTA01'  # Suffix added to the name of the finetuned model. If empty, this will be '-FT00'

dataset:
  # For now, only local datasets inside the "datasets" folder are used
  type: 'json'
  train: 'HumanJudge_train.jsonl'
  eval: 'HumanJudge_eval.jsonl'
  # Future, not yet implemented:
  use_hf_datasets: false
  hf_dataset_name: ''
  hf_splits: []

model:
  name: 'hf/flan-t5-small'
  type: 'seq2seqlm'  # Defaults to "CausalLM"
  class: ''  # If supplied, supercedes model.type

tokenizer:
  class: ''  # If supplied, uses this instead of AutoTokenizer
  add_pad_token: false  # If True, will add pad_token as the tokenizer's pad token
  pad_token: 'eos_token'  # "eos_token" will mean tokenizer.eos_token. Anything else will be taken literally.
  padding_side: 'right'  # Either "right" or "left"

from_pretrained:
  torch_dtype: ''  # Default: auto

lora:
  use_lora: false  # Set to True to create a LoRA or QLoRA adapter
  r: 8
  alpha: 32
  dropout: 0.05
  target_modules:
    - 'q'
    - 'v'
    - 'k'
    - 'o'
    - 'wi_0'
    - 'wi_1'
    - 'wo'
  bias: 'none'
  task_type: 'CAUSAL_LM'

# Quantization Settings section
quant:
  quantize: false  # Set to True to train a quantized model (must use LoRA)
  load_in_4bit: true
  bnb_4bit_quant_type: 'nf4'
  bnb_4bit_use_double_quant: true
  bnb_4bit_compute_dtype: 'bf16'

# TrainingArguments section
train_args:
  num_epochs: 1  # Int > 0, must be specified.
  load_best_model_at_end: false  # Whether to load the best model at the end of training
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 1
  warmup_steps: 100
  save_steps: 5000
  weight_decay: 0.1
  learning_rate: 0.0005
  logging_steps: 10
  gradient_checkpointing: true
  optim: 'adafactor'
  evaluation_strategy: 'epoch'
  save_strategy: 'steps'
  logging_strategy: 'epoch'
  log_level: 'warning'
